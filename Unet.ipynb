{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FJ8kS6a59r7M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "Te6UN_al-A7i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
        "    super(UNET, self).__init__()\n",
        "    self.up_sampling = nn.ModuleList()\n",
        "    self.down_sampling = nn.ModuleList()\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Down the U network\n",
        "    for feature in features:\n",
        "      self.down_sampling.append(DoubleConv(in_channels, feature))\n",
        "      in_channels = feature\n",
        "\n",
        "    # Up the U network\n",
        "    for feature in reversed(features):\n",
        "      self.up_sampling.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "      self.up_sampling.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "    self.bottle_neck = DoubleConv(features[-1], features[-1] * 2)\n",
        "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip_connections = []\n",
        "    for down_sample in self.down_sampling:\n",
        "      x = down_sample(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.max_pool(x)\n",
        "\n",
        "    x = self.bottle_neck(x)\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for i in range(0, len(self.up_sampling), 2):\n",
        "      x = self.up_sampling[i](x)\n",
        "      skip_connection = skip_connections[i//2]\n",
        "\n",
        "      if x.shape != skip_connection.shape:\n",
        "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "      x = self.up_sampling[i + 1](concat_skip)\n",
        "\n",
        "    return self.final_conv(x)"
      ],
      "metadata": {
        "id": "E_e_pf2M_jlo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((3, 1, 164, 164))\n",
        "model = UNET(in_channels=1, out_channels=1)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW-hRFUsPfrz",
        "outputId": "b0cd763c-e1a0-4c79-95c1-0c9b70155147"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-1.0468, -0.0166,  0.0301,  ...,  1.6915,  0.5362, -1.6300],\n",
            "          [ 0.9801, -0.3030,  0.6119,  ...,  0.9953,  0.8321, -0.6704],\n",
            "          [-0.0898,  0.1024,  2.3816,  ...,  0.0412, -0.6030, -0.6178],\n",
            "          ...,\n",
            "          [-0.0446, -0.5421, -0.9536,  ...,  2.4646, -0.6498, -0.7474],\n",
            "          [-0.2652,  0.1830, -2.3945,  ...,  0.1613, -1.1950, -1.2325],\n",
            "          [ 0.6813, -0.5447, -0.8322,  ...,  0.2796, -0.8650, -1.0577]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0751,  0.0246, -0.5136,  ...,  0.4104,  0.2865, -0.2959],\n",
            "          [ 0.7612, -0.4717,  0.6451,  ...,  0.3040, -0.0145, -0.9153],\n",
            "          [-1.0468, -0.4714,  0.6018,  ...,  0.0491,  1.7783,  0.4017],\n",
            "          ...,\n",
            "          [ 1.5515, -2.0278, -1.8483,  ...,  0.4439,  0.5086, -0.5200],\n",
            "          [-0.5622,  0.4031, -0.9494,  ..., -1.5475,  2.1311, -1.2994],\n",
            "          [ 1.0823,  0.2312,  0.7589,  ..., -0.4231,  1.1247, -0.7772]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3303,  0.5727, -0.0660,  ...,  0.2148, -1.4475, -1.1001],\n",
            "          [-0.7953, -1.0506,  1.0483,  ..., -0.0606, -0.4288, -1.0632],\n",
            "          [-0.6977,  0.6204,  1.2682,  ..., -0.5036,  0.3979,  0.8696],\n",
            "          ...,\n",
            "          [ 1.2259, -0.9382,  0.6458,  ...,  0.0640, -2.0215,  0.6428],\n",
            "          [ 0.1432,  0.1387,  0.3388,  ..., -0.6358, -1.2691,  0.2593],\n",
            "          [ 0.4122,  0.2079,  1.0262,  ..., -0.2089, -0.8159,  0.4246]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(x)\n",
        "\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwkddAv2OADq",
        "outputId": "779aef22-7a41-4e2b-9ded-2e01a6ab6cd7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-7.8615e-01, -9.2691e-01, -6.0194e-01,  ..., -6.1102e-01,\n",
            "           -5.9466e-01, -4.2123e-01],\n",
            "          [-3.3110e-01,  5.0412e-02, -8.5804e-02,  ..., -3.5462e-01,\n",
            "           -4.5124e-01, -2.9182e-01],\n",
            "          [-6.5551e-02, -4.8520e-01, -1.3581e+00,  ..., -1.8820e-01,\n",
            "           -1.5520e-01,  3.1639e-03],\n",
            "          ...,\n",
            "          [-5.7518e-01,  1.7181e-01, -9.2582e-02,  ..., -6.8580e-02,\n",
            "           -1.9454e-01, -4.0080e-01],\n",
            "          [-9.4960e-01, -3.5209e-01, -3.9878e-01,  ..., -3.0820e-01,\n",
            "            1.5029e-01, -3.1823e-01],\n",
            "          [-7.8362e-01, -9.5320e-01, -3.1767e-01,  ..., -3.7102e-01,\n",
            "           -6.0932e-01, -8.3625e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.1371e-01, -7.1526e-01, -5.1797e-01,  ..., -9.2383e-01,\n",
            "           -8.4946e-01, -3.7277e-01],\n",
            "          [-8.2932e-01, -1.7809e-01, -3.8386e-01,  ..., -6.7520e-01,\n",
            "           -5.2506e-01, -2.0573e-01],\n",
            "          [-9.3634e-02, -9.0712e-01, -3.1235e-01,  ..., -5.0498e-01,\n",
            "           -5.9980e-01, -4.7795e-01],\n",
            "          ...,\n",
            "          [-5.8407e-01,  2.1302e-01,  7.1952e-02,  ...,  4.0669e-01,\n",
            "           -4.8185e-01, -2.7956e-01],\n",
            "          [-7.4300e-01, -9.4989e-01, -4.8291e-01,  ..., -1.4906e-02,\n",
            "           -1.0740e-01, -1.5927e-01],\n",
            "          [-5.2224e-01, -5.9556e-01, -2.2506e-01,  ..., -1.2161e+00,\n",
            "           -5.8694e-01, -4.4059e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.9068e-01, -1.0337e+00, -4.0911e-01,  ..., -5.8985e-01,\n",
            "           -7.9712e-01, -3.6009e-01],\n",
            "          [-3.1342e-04, -2.4367e-01, -6.4197e-02,  ..., -2.6382e-01,\n",
            "           -3.8880e-01, -1.9363e-01],\n",
            "          [-5.0104e-01, -2.7902e-01, -4.5525e-01,  ..., -5.6507e-01,\n",
            "           -6.4159e-01, -1.2957e-01],\n",
            "          ...,\n",
            "          [-5.1757e-01, -3.9730e-01, -1.6993e-01,  ..., -1.7030e-01,\n",
            "            6.7767e-02,  8.3066e-02],\n",
            "          [-4.7388e-01, -8.4787e-01, -4.0920e-01,  ..., -4.6591e-01,\n",
            "           -2.0471e-01, -2.8354e-01],\n",
            "          [-4.0559e-01, -5.3141e-01, -5.2516e-01,  ..., -4.3604e-02,\n",
            "           -1.0437e+00, -8.7411e-01]]]], grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "unet = UNET(in_channels=1, out_channels=1).to(device)\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(unet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "lZb0-YZdRz9c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, num_samples, image_size):\n",
        "    self.num_samples = num_samples\n",
        "    self.image_size = image_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.num_samples\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = torch.randn(1, self.image_size, self.image_size)\n",
        "    target_mask = torch.randint(0, 2, (1, self.image_size, self.image_size)).float()\n",
        "    return image, target_mask"
      ],
      "metadata": {
        "id": "564AC2r1SN90"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomImageDataset(1000, 256)\n",
        "batch_size = 6\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "TZC5dM_BTCWB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    optimizer.zero_grad()\n",
        "    outputs = unet(inputs.to(device))\n",
        "    loss = criteria(outputs, targets.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DReFEqITTRFR",
        "outputId": "aba74d6a-0ed9-41da-ca40-1757b4faebd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n",
            "Epoch: 0, Loss: -0.0\n"
          ]
        }
      ]
    }
  ]
}